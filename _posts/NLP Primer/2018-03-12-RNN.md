---
layout : life
title: RNN Primer
category : NLP Primer
duoshuo: true
date : 2018-03-11
---

# RNN
* Reference (https://zhuanlan.zhihu.com/p/28054589)

## 网络
1. 输入x1, x2, x3, x4 ...
2. 计算隐藏层参数：
```python
h1 = f(U*x1 + W*h0 + b)
h2 = f(U*x2 + W*h1 + b)
h3 = f(U*x3 + W*h2 + b)
h4 = f(U*x4 + W*h3 + b)
... 
```
3. 输出
```python
y1 = Softmax(V*h1 + c)
y2 = Softmax(V*h2 + c)
y3 = Softmax(V*h3 + c)
y4 = Softmax(V*h4 + c)
...
```
* 注： 输入与输出等长度。所以经典RNN应用范围较小，如视频抽帧，预测下一个词语等输入序列与输出序列相同可以使用。
4. 单输出值
```
Y = Softmax(V*h4 + c)
```
* 应用：输入一段文字判断类别，情感分析（倾向）。
5. 单输入多输出
```
h1 = f(U*x + W*h0 + b)
h2 = f(U*x + W*h1 + b)
h3 = f(U*x + W*h2 + b)
h4 = f(U*x + W*h3 + b)
... 
```
* 应用：输入一个类别，生成一段话。

## 多输入多输出(Encoder-Decoder)/(Seq2Seq)
1. 构建隐层网络，得到最后一个隐层值(h4)
2. 得到c， 多种方式
* c = h4
* c = q(h4)
* c = q(h1, h2, h3, h4)
3. 把c作为单输入，输入到另外一个神经网络中。
* 应用：机器翻译，阅读理解,语音识别。

## 注意力(Attention)机制
